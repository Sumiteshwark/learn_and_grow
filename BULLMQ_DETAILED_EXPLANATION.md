# ğŸš€ **BullMQ Implementation in Sentinel - Complete Technical Guide**

## ğŸ“‹ **Table of Contents**
- [What is BullMQ?](#what-is-bullmq)
- [Why BullMQ in Sentinel?](#why-bullmq-in-sentinel)
- [Architecture Overview](#architecture-overview)
- [Core Components](#core-components)
- [Configuration Deep Dive](#configuration-deep-dive)
- [Job Lifecycle](#job-lifecycle)
- [Processing Pipeline](#processing-pipeline)
- [Error Handling & Retry Logic](#error-handling--retry-logic)
- [Dead Letter Queue](#dead-letter-queue)
- [Monitoring & Health Checks](#monitoring--health-checks)
- [API Integration](#api-integration)
- [Performance Optimization](#performance-optimization)
- [Migration Strategy](#migration-strategy)
- [Production Deployment](#production-deployment)
- [Troubleshooting Guide](#troubleshooting-guide)

---

## ğŸ¤” **What is BullMQ?**

**BullMQ** is a **Redis-backed job queue** for Node.js applications. It provides:

### **Core Features:**
- âœ… **Persistent Storage**: Jobs survive server restarts
- âœ… **Priority Queues**: High/Medium/Low priority processing
- âœ… **Automatic Retries**: Exponential backoff strategies
- âœ… **Real-time Monitoring**: Live job status updates
- âœ… **Distributed Processing**: Multiple workers across instances
- âœ… **Advanced Scheduling**: Delayed jobs, recurring tasks
- âœ… **Dead Letter Queues**: Failed job management

### **Why Not Other Solutions?**
- **vs Bull**: BullMQ is the modern successor with better TypeScript support
- **vs Redis alone**: BullMQ provides structured job management
- **vs Database queues**: Redis provides better performance for high-throughput

---

## ğŸ¯ **Why BullMQ in Sentinel?**

### **Sentinel's Requirements:**
```typescript
// Sentinel needs to handle:
// 1. Test execution jobs (potentially long-running)
// 2. High throughput during peak hours
// 3. Job persistence across deployments
// 4. Real-time progress tracking
// 5. Priority-based processing
// 6. Comprehensive error handling
```

### **BullMQ Benefits for Sentinel:**
- âœ… **Scalability**: Handle thousands of concurrent test executions
- âœ… **Reliability**: Jobs survive server restarts/crashes
- âœ… **Observability**: Real-time monitoring of test progress
- âœ… **Performance**: Redis-backed for low-latency operations
- âœ… **Flexibility**: Priority queues for different test types

### **Real-World Impact:**
```typescript
// Before: Synchronous processing (blocking)
const result = await executeTest(testDefinition); // Blocks API response

// After: Asynchronous processing (non-blocking)
const testId = await queueService.executeTest(testDefinition);
// API responds immediately with testId
// User can check progress/status later
```

---

## ğŸ—ï¸ **Architecture Overview**

### **Service Architecture:**
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Service   â”‚â”€â”€â”€â”€â”‚     Redis       â”‚â”€â”€â”€â”€â”‚ Integrations    â”‚
â”‚   (Port 3000)   â”‚    â”‚  (BullMQ Store) â”‚    â”‚   Service       â”‚
â”‚                 â”‚    â”‚                 â”‚    â”‚  (Port 3001)    â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚    â”‚                 â”‚
â”‚ â”‚  Queue      â”‚â—„â”œâ”€â”€â”€â–ºâ”‚ â”‚  Jobs       â”‚â—„â”œâ”€â”€â”€â–ºâ”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  Producer   â”‚ â”‚    â”‚ â”‚  Queue      â”‚ â”‚    â”‚ â”‚  Browser    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚    â”‚ â”‚  Engine     â”‚ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
                                              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### **Data Flow:**
```
1. User submits test â†’ API Service
2. API creates job â†’ BullMQ Queue (Redis)
3. Worker picks job â†’ Integrations Service
4. Integrations processes â†’ Browser Engine
5. Results stored â†’ Redis
6. User queries status â†’ API Service
```

### **Component Responsibilities:**

#### **API Service (Producer):**
- Accepts test execution requests
- Creates BullMQ jobs with priorities
- Provides status/result endpoints
- Handles queue management operations

#### **Redis (Store):**
- Persistent job storage
- Job state management
- Real-time progress tracking
- Distributed lock management

#### **Integrations Service (Consumer):**
- Worker processes that execute tests
- Browser automation via Playwright
- Progress reporting back to Redis
- Error handling and retries

---

## ğŸ”§ **Core Components**

### **1. Queue Configuration (`queue.config.ts`)**

```typescript
// Environment-based configuration
export const queueConfig: QueueConfig = {
  name: 'sentinel-api',
  redis: {
    host: process.env.REDIS_HOST || 'localhost',
    port: parseInt(process.env.REDIS_PORT || '6379'),
    password: process.env.REDIS_PASSWORD,
    db: parseInt(process.env.REDIS_DB || '0'),
  },
  defaultJobOptions: {
    removeOnComplete: 50,    // Keep 50 completed jobs
    removeOnFail: 20,        // Keep 20 failed jobs
    attempts: 3,             // Retry 3 times
    backoff: {
      type: 'exponential',   // Exponential backoff
      delay: 2000,          // Start with 2s delay
    },
  },
  concurrency: 5,           // 5 concurrent workers
  retentionDays: 7,         // Keep jobs for 7 days
};
```

#### **Priority System:**
```typescript
export const PRIORITY_VALUES = {
  high: 1,     // Critical tests (security, smoke)
  medium: 0,   // Standard tests
  low: -1,     // Background tests (performance)
};
```

### **2. Job Types (`job.types.ts`)**

#### **Job Data Structure:**
```typescript
interface QueueJobData {
  testDefinition: TestDefinition;    // What to test
  options: QueueJobOptions;         // How to run it
  metadata: QueueJobMetadata;       // Who/when/why
}

interface QueueJobOptions {
  priority: 'high' | 'medium' | 'low';
  timeout: number;                  // Max execution time
  tags: string[];                  // Test categorization
  retryAttempts?: number;
}

interface QueueJobMetadata {
  tenantId: string;                // Multi-tenant support
  userId?: string;                 // Who triggered the test
  requestId?: string;              // Request correlation
  createdAt: string;               // When job was created
  source?: 'api' | 'scheduler' | 'webhook';
}
```

#### **Job Result Structure:**
```typescript
interface QueueJobResult {
  success: boolean;
  status: TestExecutionStatus;
  result?: TestResult;             // Test execution results
  error?: QueueJobError;           // Error details
  executionTime: number;           // How long it took
  completedAt: string;             // When it finished
  metadata: {
    startedAt: string;
    workerId?: string;             // Which worker processed it
    attemptNumber: number;         // Retry attempt number
    totalAttempts: number;         // Total retry attempts
  };
}
```

### **3. Queue Service (`queue-test-executor.service.ts`)**

#### **Main Service Interface:**
```typescript
class QueueTestExecutorService {
  async executeTest(testDefinition, options): Promise<string> {
    // 1. Prepare job data
    const jobData = {
      testDefinition,
      options: { priority: 'medium', timeout: 60000, ... },
      metadata: { tenantId, userId, createdAt: now() }
    };

    // 2. Add to BullMQ queue
    const jobId = await this.queue.addJob(jobData);

    // 3. Return job ID for status tracking
    return jobId;
  }

  async getTestStatus(testId): Promise<QueueJobStatus> {
    // Query job status from Redis
    const job = await this.queue.getJobStatus(testId);
    return this.mapJobToStatus(job);
  }
}
```

### **4. Job Processor (`test-job.processor.ts`)**

#### **Processing Pipeline:**
```typescript
export async function testJobProcessor(job: Job<QueueJobData>): Promise<QueueJobResult> {
  const startTime = Date.now();
  const { testDefinition, options } = job.data;

  try {
    // 1. Update progress (0%)
    await updateProgress(job, { percentage: 0, ... });

    // 2. Validate job data
    validateJobData(job.data);

    // 3. Execute test with timeout protection
    const result = await Promise.race([
      executeTestWithProgress(job, testDefinition, options),
      createTimeoutPromise(timeout, job.id)
    ]);

    // 4. Update final progress (100%)
    await updateProgress(job, { percentage: 100, ... });

    return {
      success: result.success,
      status: result.success ? 'completed' : 'failed',
      result,
      executionTime: Date.now() - startTime,
      completedAt: new Date().toISOString(),
      metadata: { /* execution details */ }
    };

  } catch (error) {
    // Handle errors with categorization
    const jobError = categorizeError(error);
    return createErrorResult(jobError, startTime);
  }
}
```

---

## âš™ï¸ **Configuration Deep Dive**

### **Environment Variables:**
```bash
# Queue System Control
USE_QUEUE_SYSTEM=true              # Enable/disable queue system
USE_EXTERNAL_EXECUTOR=false        # Use separate executor service

# Redis Configuration
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=your-password
REDIS_DB=0

# Queue Performance
QUEUE_CONCURRENCY=5                # Concurrent workers
QUEUE_RETENTION_DAYS=7             # Job retention
QUEUE_REMOVE_ON_COMPLETE=50        # Keep N completed jobs
QUEUE_REMOVE_ON_FAIL=20            # Keep N failed jobs

# Retry Configuration
QUEUE_DEFAULT_ATTEMPTS=3            # Default retry count
QUEUE_BACKOFF_DELAY=2000            # Initial backoff delay

# Health Monitoring
QUEUE_MAX_WAITING=100               # Max waiting jobs threshold
QUEUE_MAX_ACTIVE=50                 # Max active jobs threshold
QUEUE_MAX_FAILED=20                 # Max failed jobs threshold
```

### **Priority-Based Timeouts:**
```typescript
const timeouts = {
  high: 300000,    // 5 minutes (critical tests)
  medium: 600000,  // 10 minutes (standard tests)
  low: 1200000,    // 20 minutes (background tests)
};
```

### **Error-Specific Retry Logic:**
```typescript
const retryConfigs = {
  network: { attempts: 3, delay: 5000 },    // Network issues
  timeout: { attempts: 2, delay: 10000 },   // Test timeouts
  browser: { attempts: 2, delay: 3000 },    // Browser errors
  system: { attempts: 1, delay: 60000 },    // System issues
  validation: { attempts: 0, delay: 0 },    // Don't retry validation errors
};
```

---

## ğŸ”„ **Job Lifecycle**

### **Complete Job Flow:**

```
1. CREATED     â†’ Job added to queue (waiting state)
2. WAITING     â†’ Job waits in priority queue
3. ACTIVE      â†’ Worker picks up job for processing
4. PROGRESS    â†’ Real-time updates during execution
5. COMPLETED   â†’ Job finishes successfully
   â””â”€ FAILED   â†’ Job fails (retry or move to DLQ)
      â””â”€ DEAD  â†’ Job moved to dead letter queue
```

### **State Transitions:**

```typescript
enum TestExecutionStatus {
  PENDING    = 'pending',    // Job created, waiting in queue
  RUNNING    = 'running',    // Worker actively processing
  COMPLETED  = 'completed',  // Successful execution
  FAILED     = 'failed',     // Failed after retries
  TIMEOUT    = 'timeout',    // Exceeded time limit
  CANCELLED  = 'cancelled'   // Manually cancelled
}
```

### **Progress Tracking:**
```typescript
interface QueueJobProgress {
  percentage: number;        // 0-100 completion
  currentStep: number;       // Current test step
  totalSteps: number;        // Total test steps
  stepName?: string;         // "Login test", "Navigation test"
  message?: string;          // "Clicking login button"
  updatedAt: string;         // Last update timestamp
}
```

---

## ğŸ”¬ **Processing Pipeline**

### **Step-by-Step Execution:**

```typescript
async function testJobProcessor(job) {
  // 1. Initialize
  const startTime = Date.now();
  updateProgress(job, { percentage: 0, stepName: 'Initializing' });

  // 2. Validate
  validateJobData(job.data);
  updateProgress(job, { percentage: 5, stepName: 'Validation complete' });

  // 3. Setup Browser
  const browser = await setupBrowser();
  updateProgress(job, { percentage: 10, stepName: 'Browser ready' });

  // 4. Execute Test Steps
  for (let i = 0; i < testDefinition.steps.length; i++) {
    const step = testDefinition.steps[i];
    updateProgress(job, {
      percentage: 10 + (i / testDefinition.steps.length) * 80,
      currentStep: i + 1,
      stepName: step.name || `Step ${i + 1}`
    });

    await executeStep(step, browser);
  }

  // 5. Cleanup
  updateProgress(job, { percentage: 95, stepName: 'Cleaning up' });
  await browser.close();

  // 6. Finalize
  updateProgress(job, { percentage: 100, stepName: 'Complete' });

  return {
    success: true,
    executionTime: Date.now() - startTime,
    // ... result data
  };
}
```

### **Timeout Protection:**
```typescript
const timeoutPromise = createTimeoutPromise(timeout, job.id);
const result = await Promise.race([
  executeTestWithProgress(job, testDefinition, options),
  timeoutPromise  // Will throw if timeout exceeded
]);
```

### **Progress Updates:**
```typescript
async function updateProgress(job, progress) {
  await job.updateProgress(progress);

  // Also emit to Redis for real-time monitoring
  await job.update({
    opts: {
      ...job.opts,
      progress: progress
    }
  });
}
```

---

## ğŸš¨ **Error Handling & Retry Logic**

### **Error Categorization:**
```typescript
function categorizeError(error: Error): QueueJobError {
  if (error.message.includes('timeout')) {
    return {
      code: 'TIMEOUT',
      message: 'Test execution timed out',
      category: 'timeout',
      retryable: true
    };
  }

  if (error.message.includes('network')) {
    return {
      code: 'NETWORK_ERROR',
      message: 'Network connectivity issue',
      category: 'network',
      retryable: true
    };
  }

  if (error.message.includes('validation')) {
    return {
      code: 'VALIDATION_ERROR',
      message: 'Invalid test definition',
      category: 'validation',
      retryable: false  // Don't retry validation errors
    };
  }

  return {
    code: 'UNKNOWN_ERROR',
    message: error.message,
    category: 'unknown',
    retryable: true
  };
}
```

### **Retry Strategy:**

#### **Exponential Backoff:**
```typescript
backoff: {
  type: 'exponential',
  delay: 2000,  // Initial delay: 2 seconds
  // Next retry: 4 seconds
  // Next retry: 8 seconds
  // Next retry: 16 seconds
}
```

#### **Category-Specific Retries:**
```typescript
const retryStrategy = {
  network: { attempts: 3, delay: 5000 },   // Network: 3 tries, 5s delay
  timeout: { attempts: 2, delay: 10000 },  // Timeout: 2 tries, 10s delay
  browser: { attempts: 2, delay: 3000 },   // Browser: 2 tries, 3s delay
  system: { attempts: 1, delay: 60000 },   // System: 1 try, 60s delay
  validation: { attempts: 0 },             // Validation: No retries
};
```

### **Dead Letter Queue Integration:**
```typescript
if (job.attemptsMade >= maxRetries) {
  // Move to dead letter queue
  await deadLetterQueue.add(job.id, job.data, {
    reason: 'max_retries_exceeded',
    finalError: error
  });
}
```

---

## âš°ï¸ **Dead Letter Queue**

### **Purpose:**
- Store permanently failed jobs
- Prevent infinite retry loops
- Enable manual inspection and recovery
- Track failure patterns for debugging

### **Implementation:**
```typescript
class DeadLetterQueue {
  async add(jobId: string, jobData: any, reason: string) {
    const dlqJob = await this.queue.add('dead-letter', {
      originalJobId: jobId,
      jobData,
      reason,
      failedAt: new Date().toISOString()
    });
    return dlqJob.id;
  }

  async getFailedJobs(limit: number = 50, offset: number = 0) {
    const jobs = await this.queue.getJobs(['completed'], {
      size: limit,
      start: offset
    });
    return jobs.map(job => ({
      id: job.id,
      originalJobId: job.data.originalJobId,
      reason: job.data.reason,
      failedAt: job.data.failedAt,
      jobData: job.data.jobData
    }));
  }

  async requeueFailedJob(dlqJobId: string) {
    const dlqJob = await this.queue.getJob(dlqJobId);
    if (!dlqJob) throw new Error('DLQ job not found');

    // Requeue to original queue
    await originalQueue.add(
      dlqJob.data.jobData.testDefinition.name,
      dlqJob.data.jobData,
      { priority: 'low' } // Lower priority for requeued jobs
    );

    // Remove from DLQ
    await dlqJob.remove();
  }
}
```

---

## ğŸ“Š **Monitoring & Health Checks**

### **Queue Metrics:**
```typescript
interface QueueMetrics {
  waiting: number;          // Jobs waiting in queue
  active: number;           // Jobs being processed
  completed: number;        // Successfully completed jobs
  failed: number;           // Failed jobs
  delayed: number;          // Delayed jobs
  paused: boolean;          // Is queue paused?

  totalProcessed: number;   // Total jobs processed
  totalFailed: number;      // Total failures
  processingRate: number;   // Jobs per minute
  avgProcessingTime: number; // Average execution time
  lastProcessedAt?: string;  // Last activity timestamp
}
```

### **Health Check Logic:**
```typescript
function checkQueueHealth(metrics: QueueMetrics): 'healthy' | 'degraded' | 'unhealthy' {
  // Check thresholds
  if (metrics.waiting > 100) return 'degraded';  // Too many waiting
  if (metrics.active > 50) return 'degraded';    // Too many active
  if (metrics.failed > 20) return 'unhealthy';   // Too many failures

  // Check processing rate
  if (metrics.processingRate < 5) return 'degraded'; // Too slow

  // Check staleness
  const lastActivity = Date.now() - new Date(metrics.lastProcessedAt).getTime();
  if (lastActivity > 300000) return 'degraded'; // No activity for 5 minutes

  return 'healthy';
}
```

### **Real-time Monitoring:**
```typescript
// Event listeners for monitoring
queue.on('waiting', (jobId) => {
  console.log(`Job ${jobId} is waiting in queue`);
});

queue.on('active', (jobId, prev) => {
  console.log(`Job ${jobId} started processing`);
});

queue.on('completed', (jobId, result) => {
  console.log(`Job ${jobId} completed successfully`);
});

queue.on('failed', (jobId, err) => {
  console.log(`Job ${jobId} failed: ${err.message}`);
});

queue.on('progress', (jobId, progress) => {
  console.log(`Job ${jobId} progress: ${progress.percentage}%`);
});
```

---

## ğŸ”— **API Integration**

### **REST API Endpoints:**

#### **Execute Test:**
```http
POST /api/v1/tests/execute
Authorization: Bearer <api-key>
Content-Type: application/json

{
  "testDefinition": { /* test data */ },
  "options": {
    "priority": "high",
    "timeout": 30000,
    "tags": ["smoke", "critical"]
  }
}

Response:
{
  "success": true,
  "message": "Test execution started successfully",
  "timestamp": "2024-01-01T10:00:00.000Z",
  "data": {
    "testId": "job-12345"
  }
}
```

#### **Check Status:**
```http
GET /api/v1/tests/job-12345/status
Authorization: Bearer <api-key>

Response:
{
  "success": true,
  "message": "Test status retrieved successfully",
  "timestamp": "2024-01-01T10:00:05.000Z",
  "data": {
    "id": "job-12345",
    "status": "running",
    "priority": "high",
    "progress": {
      "percentage": 65,
      "currentStep": 3,
      "totalSteps": 5,
      "stepName": "Login verification",
      "message": "Checking user credentials"
    },
    "startedAt": "2024-01-01T10:00:00.000Z"
  }
}
```

#### **Queue Management:**
```http
GET /api/v1/queue/stats      # Get queue metrics
POST /api/v1/queue/pause     # Pause queue processing
POST /api/v1/queue/resume    # Resume queue processing
POST /api/v1/queue/jobs/{id}/cancel  # Cancel specific job
POST /api/v1/queue/jobs/{id}/retry   # Retry failed job
```

### **Service Integration:**
```typescript
// In test execution service
const testExecutorService = getHybridTestExecutorService();

// Queue-based execution
const testId = await testExecutorService.executeTest(testDefinition, {
  priority: 'high',
  userId: request.auth?.userId,
  requestId: request.headers['x-request-id']
});

// Status checking
const status = await testExecutorService.getTestStatus(testId);
```

---

## âš¡ **Performance Optimization**

### **Redis Configuration:**
```redis.conf
# Memory optimization
maxmemory 256mb
maxmemory-policy allkeys-lru

# Persistence for job durability
save 900 1
save 300 10
save 60 10000

# Connection pooling
tcp-keepalive 300
timeout 300

# Performance tuning
tcp-backlog 511
databases 16
```

### **Worker Concurrency:**
```typescript
// Optimal concurrency based on server capacity
const optimalConcurrency = Math.max(1, Math.floor(os.cpus().length / 2));

// For I/O bound operations (like browser automation)
const browserConcurrency = Math.min(optimalConcurrency, 5);
```

### **Connection Pooling:**
```typescript
// BullMQ automatically handles connection pooling
const queue = new Queue('test-execution', {
  connection: {
    host: 'localhost',
    port: 6379,
    maxRetriesPerRequest: null,  // Important for BullMQ
    retryDelayOnFailover: 100,
    lazyConnect: true,
  }
});
```

### **Memory Management:**
```typescript
// Limit completed jobs in memory
defaultJobOptions: {
  removeOnComplete: 50,    // Keep recent completed jobs
  removeOnFail: 20,        // Keep recent failed jobs
}

// Periodic cleanup
setInterval(async () => {
  await queue.clean(24 * 60 * 60 * 1000, 100); // Clean old jobs
}, 60 * 60 * 1000); // Hourly cleanup
```

---

## ğŸ”„ **Migration Strategy**

### **Hybrid Approach:**
```typescript
class HybridTestExecutorService {
  constructor(
    private queueService: QueueTestExecutorService,
    private directService: DirectTestExecutorService
  ) {}

  async executeTest(testDefinition, options) {
    // Check if queue system is enabled
    if (process.env.USE_QUEUE_SYSTEM === 'true') {
      return this.queueService.executeTest(testDefinition, options);
    } else {
      // Fallback to direct execution
      return this.directService.executeTest(testDefinition, options);
    }
  }
}
```

### **Gradual Rollout:**
```bash
# Phase 1: Enable queue for low-priority tests
export QUEUE_LOW_PRIORITY_ONLY=true

# Phase 2: Enable for all tests
export USE_QUEUE_SYSTEM=true

# Phase 3: Disable direct execution
export USE_DIRECT_EXECUTION=false
```

### **Rollback Plan:**
```typescript
// Automatic fallback if queue is unavailable
async function executeWithFallback(testDefinition, options) {
  try {
    return await queueService.executeTest(testDefinition, options);
  } catch (queueError) {
    console.warn('Queue unavailable, falling back to direct execution');
    return await directService.executeTest(testDefinition, options);
  }
}
```

---

## ğŸš€ **Production Deployment**

### **Infrastructure Setup:**
```yaml
# docker-compose.yml for production
version: '3.8'
services:
  redis:
    image: redis:7-alpine
    command: redis-server --appendonly yes
    volumes:
      - redis-data:/data
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 3s
      retries: 3

  api:
    build: ./packages/@sentinel/services/api
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - USE_QUEUE_SYSTEM=true
      - QUEUE_CONCURRENCY=10
    depends_on:
      redis:
        condition: service_healthy

  integrations:
    build: ./packages/@sentinel/integrations
    environment:
      - REDIS_HOST=redis
      - REDIS_PORT=6379
    depends_on:
      redis:
        condition: service_healthy

volumes:
  redis-data:
```

### **Kubernetes Deployment:**
```yaml
# Redis StatefulSet
apiVersion: apps/v1
kind: StatefulSet
metadata:
  name: sentinel-redis
spec:
  replicas: 1
  template:
    spec:
      containers:
      - name: redis
        image: redis:7-alpine
        ports:
        - containerPort: 6379
        volumeMounts:
        - name: redis-data
          mountPath: /data
        resources:
          requests:
            memory: "256Mi"
            cpu: "100m"
          limits:
            memory: "512Mi"
            cpu: "200m"
```

### **Scaling Strategy:**
```yaml
# Horizontal Pod Autoscaling
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: sentinel-api-hpa
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: sentinel-api
  minReplicas: 2
  maxReplicas: 10
  metrics:
  - type: Resource
    resource:
      name: cpu
      target:
        type: Utilization
        averageUtilization: 70
```

---

## ğŸ”§ **Troubleshooting Guide**

### **Common Issues:**

#### **1. Redis Connection Errors:**
```bash
# Check Redis connectivity
redis-cli ping

# Check Redis logs
docker logs sentinel-redis

# Test connection from application
curl http://localhost:3000/api/v1/queue/health
```

#### **2. High Queue Depth:**
```typescript
// Check queue metrics
const metrics = await queueService.getQueueMetrics();
console.log('Queue depth:', metrics.waiting);

// Scale up workers
export QUEUE_CONCURRENCY=10

// Check for resource bottlenecks
top -p $(pgrep -f "node.*worker")
```

#### **3. Job Stalling:**
```typescript
// Find stalled jobs
const stalledJobs = await queue.getJobs(['active'], 0, 100, true);
stalledJobs.forEach(job => {
  if (Date.now() - job.processedOn > 300000) { // 5 minutes
    console.log('Stalled job:', job.id);
    job.moveToFailed(new Error('Job stalled'), true);
  }
});
```

#### **4. Memory Issues:**
```typescript
// Check Redis memory usage
redis-cli info memory

// Clean up old jobs
await queue.clean(24 * 60 * 60 * 1000, 1000); // 24 hours, 1000 jobs

// Monitor job retention
export QUEUE_REMOVE_ON_COMPLETE=20
export QUEUE_REMOVE_ON_FAIL=10
```

#### **5. Worker Performance:**
```typescript
// Monitor worker performance
queue.on('completed', (jobId, result) => {
  console.log(`Job ${jobId} took ${result.executionTime}ms`);
});

// Check for resource leaks
const memUsage = process.memoryUsage();
if (memUsage.heapUsed > 100 * 1024 * 1024) { // 100MB
  console.warn('High memory usage detected');
}
```

### **Debug Commands:**
```bash
# Check queue status
redis-cli KEYS "bull:*"

# Monitor queue in real-time
redis-cli MONITOR

# View job details
redis-cli HGETALL "bull:test-execution:123"

# Check worker status
ps aux | grep worker
```

### **Performance Tuning:**
```typescript
// Optimize BullMQ settings
const optimizedQueue = new Queue('test-execution', {
  connection: {
    maxRetriesPerRequest: null,
    retryDelayOnFailover: 100,
    lazyConnect: true,
  },
  defaultJobOptions: {
    removeOnComplete: 50,
    removeOnFail: 20,
    attempts: 3,
    backoff: {
      type: 'exponential',
      delay: 2000,
    },
  },
});

// Connection pooling
const worker = new Worker('test-execution', processor, {
  connection: {
    maxRetriesPerRequest: null,
  },
  concurrency: Math.max(1, os.cpus().length - 1),
});
```

---

## ğŸ¯ **Best Practices**

### **1. Job Design:**
- Keep jobs small and focused
- Include comprehensive metadata
- Handle failures gracefully
- Use appropriate priorities

### **2. Monitoring:**
- Set up comprehensive logging
- Monitor queue depth and processing rates
- Alert on failure thresholds
- Track performance metrics

### **3. Error Handling:**
- Implement proper retry strategies
- Use dead letter queues for unrecoverable failures
- Categorize errors for better handling
- Provide detailed error information

### **4. Scaling:**
- Design for horizontal scaling
- Use connection pooling
- Monitor resource usage
- Plan for peak loads

### **5. Reliability:**
- Enable job persistence
- Implement health checks
- Set up proper monitoring
- Plan for failure scenarios

---

## ğŸ“š **Additional Resources**

- [BullMQ Official Documentation](https://docs.bullmq.io/)
- [Redis Documentation](https://redis.io/documentation)
- [BullMQ GitHub Repository](https://github.com/taskforcesh/bullmq)
- [Redis Best Practices](https://redis.io/topics/best-practices)

---

## ğŸ‰ **Conclusion**

BullMQ provides Sentinel with a robust, scalable job queue system that can handle thousands of concurrent test executions while maintaining reliability and observability. The implementation includes:

- âœ… **Comprehensive job management** with priorities and retries
- âœ… **Real-time monitoring** and progress tracking
- âœ… **Error handling** with dead letter queues
- âœ… **Scalability** through Redis-backed persistence
- âœ… **Production readiness** with health checks and metrics
- âœ… **Migration support** with hybrid execution modes

This BullMQ implementation enables Sentinel to process test executions asynchronously, providing better user experience and system reliability for large-scale test automation workflows.
